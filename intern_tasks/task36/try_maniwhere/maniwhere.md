# 训练环境：
CPU：i9 13900K
GPU: RTX 4090

# 实验结果：
1. 不更改官方repo的参数配置，直接在单卡4090上训练 ur5_lift 配置
2. 五天时间训练了 180000 frames，训练与评估的 log 见 `maniwhere_log` 文件夹, 需要有稳定的表现大概还需要三倍的训练时长

# 算法调研：
1. 训练原理
	1. 主要是两部分, 一个visual encoder, 这一部分包含一个 resnet18 的backbone + 一个 STN 模块, 两个摄像头, 一个固定视角, 一个移动视角。采用 infoNCE, 通过对比学习策略让网络对于不同视角的图像输出比较接近的视觉特征
	2. 随后用提取到的视觉特征来做强化学习,进行行为策略的学习
2. 如何迁移到实机
	1. 在真机部署的部分, 直接zero-shot迁移过去, 比较独特的是有三重泛化性
		1. 不同视角的泛化性
		2. 不同外表的泛化性(比如桌面,比如物体表面材质和颜色)
		3. 不同机械臂的泛化性
	2. 值得注意的是，在附录中, 还提到对于不同的物体和形状都有不错的泛化性，不会对学习过程中特定形态的物体产生过拟合